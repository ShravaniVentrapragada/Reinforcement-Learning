# -*- coding: utf-8 -*-
"""Team_13_Ventrapragada_Q_learning (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u1gp2QVAJ029z5X2eCw7XEUUVUkms36C

# Name: Shravani Sai Ventrapragada
# 122627419
# Reinforcement Learning

# Problem Statement
The required grid problem is given below in the image.
 The probabity to go into the forward is taken to be 0.8 and the probabity to go left or right is taken to be 0.1

![1_S3oszDubmqzfuu2vRnn3yw.png](data:image/png;base64,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)

Epsilon: Giving maximum greedy factor to the agent to learn and explore the most from the environment 

Gamma: Discount factor is kept between 0 and 1 because if 0 never learns if 1 keeps on learning; This helps tune the vision in the long run

In Q-learning the agents action is said to be non-deterministic that is the agent will not be able to go in the direction where it was supposed to go.

#Algorithm
Step 1: Importing Libraries

Step 2: Declare all Global Variables

Step 3: Set up the environment

Step 4:Define the reward function

Step 5: Define the end conditions 

Step 6: Define the action and probabilty

Step 7: Define next position for the agent

Step 8: Print the grid

Step 9: Recording positions and actions taken at each grid point and Intiating Q-Values

Step 10: Chooses the action it has to take in the current state

Step 11: Performs the chosen action

Step 12: Reset the self at the end of episodes

Step 13: This block of code, show how the self is moving in the environment and after every state it chooses an action and goes to that block to perform the same. 

And updating the reward function according to the performed action in a perticular state.

Step 14: Printing all the outputs
"""

# Step 1: Importing Libraries
import numpy as np

#Step 2: Declare all Global Variables
grid_rows= 3
grid_columns = 4
winning_state = (0, 3) #Defining our winning state to be 0,3
losing_state = (1, 3) #Defining our lossing state to be  1,3
starting_position = (2, 0)
DETERMINISTIC = False


class State:
  # Step 3: Set up the environment
    def __init__(self, current_state=starting_position):
        self.board = np.zeros([grid_rows, grid_columns]) #initiating a 3*4 gridworld for the self.
        self.board[1, 1] = -1  #Intiating the inital position
        self.current_state = current_state #giving it the current state
        self.endFunc = False  #giving it an end state condition
        self.determine = DETERMINISTIC
# Step 4:Define the reward function
    def reward_Func(self):
        if self.current_state == winning_state:
            return 1
        elif self.current_state == losing_state:
            return -1
        else:
            return 0
#  Step 5: Define the end conditions 
    def isendFunc(self):
        if (self.current_state == winning_state) or (self.current_state == losing_state):
            self.endFunc = True
# Step 6: Define the action and probabilty
    def _chooseProbability(self, current_action):
        if current_action == "north":
            return np.random.choice(["north", "west", "east"], p=[0.8, 0.1, 0.1])
        if current_action == "south":
            return np.random.choice(["south", "west", "east"], p=[0.8, 0.1, 0.1])
        if current_action == "west":
            return np.random.choice(["west", "north", "south"], p=[0.8, 0.1, 0.1])
        if current_action == "east":
            return np.random.choice(["east", "north", "south"], p=[0.8, 0.1, 0.1])
# Step 7: Define next position for the agent
    def next_Position(self, current_action):
        """
        current_action: north, south, west, east
        -------------
        0 | 1 | 2| 3|
        1 |
        2 |
        return next position on board
        """
        if self.determine:
            if current_action == "north":
                next_State = (self.current_state[0] - 1, self.current_state[1])
            elif current_action == "south":
                next_State = (self.current_state[0] + 1, self.current_state[1])
            elif current_action == "west":
                next_State = (self.current_state[0], self.current_state[1] - 1)
            else:
                next_State = (self.current_state[0], self.current_state[1] + 1)
            self.determine = False
        else:
            # Giving it the non-deterministic environment
            current_action = self._chooseProbability(current_action)
            self.determine = True
            next_State = self.next_Position(current_action)

         #If going to the next state is valid
        if (next_State[0] >= 0) and (next_State[0] <= 2):
            if (next_State[1] >= 0) and (next_State[1] <= 3):
                if next_State != (1, 1):
                    return next_State
        return self.current_state
# Step 8: Print the grid
    def dispBoard(self):
        self.board[self.current_state] = 1
        for i in range(0, grid_rows):
            print('-----------------')
            out = '| '
            for j in range(0, grid_columns):
                if self.board[i, j] == 1:
                    token = '*'
                if self.board[i, j] == -1:
                    token = 'z'
                if self.board[i, j] == 0:
                    token = '0'
                out += token + ' | '
            print(out)
        print('-----------------')


class Agent:
# Step 9: Recording positions and actions taken at each grid point and Intiating Q-Values
    def __init__(self):
        self.allStates = []  
        self.allActions = ["north", "south", "west", "east"]
        self.State = State()
        self.endFunc = self.State.endFunc
        self.learning_rate = 0.2
        self.epsilon = 0.3
        self.Gamma_discountfactor = 0.9
        self.qValues = {}
        for i in range(grid_rows):
            for j in range(grid_columns):
                self.qValues[(i, j)] = {}
                for a in self.allActions:
                    self.qValues[(i, j)][a] = 0 
# Step 10: Chooses the action it has to take in the current state
    def choosecurrent_action(self):
        bot_next_reward = 0
        current_action = ""

        if np.random.uniform(0, 1) <= self.epsilon:
            current_action = np.random.choice(self.allActions)
        else:
            for a in self.allActions:
                current_position = self.State.current_state
                next_position-
                nextReward = self.qValues[current_position][a]
                if nextReward >= bot_next_reward:
                    current_action = a
                    bot_next_reward = nextReward
        return current_action
# Step 11: Performs the chosen action
    def takecurrent_action(self, current_action):
        position = self.State.next_Position(current_action)
        return State(current_state=position)
# Step 12: Reset the self at the end of episodes
    def reset(self):
        self.allStates = []
        self.State = State()
        self.endFunc = self.State.endFunc
# Step 13: 
# This block of code, show how the self is moving in the environment and after every state it 
# chooses an action and goes to that block to perform the same. 
# And updating the reward function according to the performed action in a perticular state.
    def game(self, episodes=10):
        i = 0
        while i < episodes:
            if self.State.endFunc:
                # back propagating the reward when  the episodes end 
                rewardofBot = self.State.reward_Func()
                for a in self.allActions:
                    self.qValues[self.State.current_state][a] = rewardofBot
                print("Game End Reward", rewardofBot)
                for s in reversed(self.allStates):
                    current_q_value = self.qValues[s[0]][s[1]]
                    rewardofBot = current_q_value + self.learning_rate * (self.Gamma_discountfactor * rewardofBot - current_q_value)
                    self.qValues[s[0]][s[1]] = round(rewardofBot, 3)
                self.reset()
                i += 1
            else:
                current_action = self.choosecurrent_action()

                self.allStates.append([(self.State.current_state), current_action])
                print("Current Position of the bot {} Current action of the bot {}".format(self.State.current_state, current_action))
                self.State = self.takecurrent_action(current_action)
                # Episode ends here
                self.State.isendFunc()
                print("Next State of the self bot", self.State.current_state)
                print("---------------------")
                self.endFunc = self.State.endFunc

# Step 14: Printing all the outputs
if __name__ == "__main__":
    ag = Agent()
    print("initial Q-values ... \n")
    print(ag.qValues)

    ag.game(300)
    print("latest Q-values ... \n")
    print(ag.qValues)



